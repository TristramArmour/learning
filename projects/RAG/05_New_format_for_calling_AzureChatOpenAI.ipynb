{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like it will be good - if this works we can make a RAG application (put into class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "import pandas as pd\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\workspace\\\\APIKEY_personal.ini']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load config\n",
    "from configparser import ConfigParser\n",
    "c = ConfigParser()\n",
    "c.read(r\"C:\\workspace\\APIKEY_personal.ini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the baseline configuration of the OpenAI library for Azure OpenAI Service.\n",
    "OPENAI_API_KEY = c[\"AZURE_4o-mini\"][\"API_KEY\"]\n",
    "OPENAI_DEPLOYMENT_NAME =  c[\"AZURE_4o-mini\"][\"CHATGPT_MODEL\"]\n",
    "MODEL_NAME = c[\"AZURE_4o-mini\"][\"CHATGPT_MODEL\"]\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = c[\"AZURE_4o-mini\"][\"API_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = c[\"AZURE_4o-mini\"][\"OPENAI_API_VERSION\"]\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = c[\"AZURE_4o-mini\"][\"OPENAI_API_BASE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a connection to the LLM from Azure OpenAI Service via LangChain.\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "    model_name=MODEL_NAME, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 28, 'total_tokens': 32, 'completion_tokens_details': None}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_878413d04d', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-6b68b471-1b5f-4c35-8e83-e973bf3ebff3-0', usage_metadata={'input_tokens': 28, 'output_tokens': 4, 'total_tokens': 32})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a simple prompt to validate the connection with LLM from Azure OpenAI Service.\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful translator. Translate the user sentence to French.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
