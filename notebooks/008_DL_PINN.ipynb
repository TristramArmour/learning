{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physics-informed Neural Networks (PINN) example\n",
    "\n",
    "https://towardsdatascience.com/solving-differential-equations-with-neural-networks-afdcf7b8bcc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_inputs: int = 1,\n",
    "        num_layers: int = 1,\n",
    "        num_neurons: int = 5,\n",
    "        act: nn.Module = nn.Tanh(),\n",
    "    ) -> None:\n",
    "        \"\"\"Basic neural network architecture with linear layers\n",
    "        \n",
    "        Args:\n",
    "            num_inputs (int, optional): the dimensionality of the input tensor\n",
    "            num_layers (int, optional): the number of hidden layers\n",
    "            num_neurons (int, optional): the number of neurons for each hidden layer\n",
    "            act (nn.Module, optional): the non-linear activation function to use for stitching\n",
    "                linear layers togeter\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_neurons = num_neurons\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # input layer\n",
    "        layers.append(nn.Linear(self.num_inputs, num_neurons))\n",
    "\n",
    "        # hidden layers with linear layer and activation\n",
    "        for _ in range(num_layers):\n",
    "            layers.extend([nn.Linear(num_neurons, num_neurons), act])\n",
    "\n",
    "        # output layer\n",
    "        layers.append(nn.Linear(num_neurons, 1))\n",
    "\n",
    "        # build the network\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(x.reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import functional_call, grad, vmap\n",
    "\n",
    "model = LinearNN()\n",
    "\n",
    "# notice that `functional_call` supports batched inputs by default\n",
    "# thus there is not need to call vmap on it, as it's instead the case\n",
    "# for the derivative calls\n",
    "def f(x: torch.Tensor, params: dict[str, torch.nn.Parameter]) -> torch.Tensor:\n",
    "    return functional_call(model, params_dict, (x, ))\n",
    "\n",
    "# return function for computing higher order gradients with respect\n",
    "# to input by simply composing `grad` calls and use again `vmap` for\n",
    "# efficient batching of the input\n",
    "dfdx = vmap(grad(f), in_dims=(0, None))\n",
    "d2fdx2 = vmap(grad(grad(f)), in_dims=(0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1.0  # rate of maximum population growth parameterizing the equation\n",
    "X_BOUNDARY = 0.0  # boundary condition coordinate\n",
    "F_BOUNDARY = 0.5  # boundary condition value\n",
    "\n",
    "def loss_fn(params: torch.Tensor, x: torch.Tensor):\n",
    "\n",
    "    # interior loss\n",
    "    f_value = f(x, params)\n",
    "    interior = dfdx(x, params) - R * f_value * (1 - f_value)\n",
    "\n",
    "    # boundary loss\n",
    "    x0 = X_BOUNDARY\n",
    "    f0 = F_BOUNDARY\n",
    "    x_boundary = torch.tensor([x0])\n",
    "    f_boundary = torch.tensor([f0])\n",
    "    boundary = f(x_boundary, params) - f_boundary\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss_value = loss(interior, torch.zeros_like(interior)) + loss(\n",
    "        boundary, torch.zeros_like(boundary)\n",
    "    )\n",
    "\n",
    "    return loss_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
